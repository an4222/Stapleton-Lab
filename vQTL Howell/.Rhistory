colnames(routvdf) = c("SNP Name",
"Position (cM)",
"Mean LOD",
"Mean P Value",
"Variance LOD",
"Variance P Value",
"Joint LOD",
"Joint P Value",
"A Mean Est",
"A Mean Lower Bound",
"A Mean Upper Bound",
"A Standard Deviation Est",
"A Standard Deviation Lower Bound",
"A Standard Deviation Upper Bound",
"B Mean Est",
"B Mean Lower Bound",
"B Mean Upper Bound",
"B Standard Deviation Est",
"B Standard Deviation Lower Bound",
"B Standard Deviation Upper Bound")
class(routvdf$`A Mean Est`)
x = y[1]
tempm =  effect.sizes(cross = random,
phenotype.name = "height.in.",
genotype.names = c("AA","BB"),
focal.groups = routv$result$loc.name[x])
class(tempm)
tempv = c(tempm[1,2:7],tempm[2,2:7])
class(tempv)
rsizedf = sapply(y, function(x){
tempm =  effect.sizes(cross = random,
phenotype.name = "height.in.",
genotype.names = c("AA","BB"),
focal.groups = routv$result$loc.name[x])
tempv = c(tempm[1,2:7],tempm[2,2:7])
return(unlist(tempv))
})
routvdf<- data.frame(routv$result$loc.name,
routv$result$pos,
routv$result$mean.lod,
routv$result$mean.asymp.p,
routv$result$var.lod,
routv$result$var.asymp.p,
routv$result$joint.lod,
routv$result$joint.asymp.p)
routvdf = routvdf[-c(458,2482,2483),]
routvdf = cbind(routvdf,t(rsizedf))
colnames(routvdf) = c("SNP Name",
"Position (cM)",
"Mean LOD",
"Mean P Value",
"Variance LOD",
"Variance P Value",
"Joint LOD",
"Joint P Value",
"A Mean Est",
"A Mean Lower Bound",
"A Mean Upper Bound",
"A Standard Deviation Est",
"A Standard Deviation Lower Bound",
"A Standard Deviation Upper Bound",
"B Mean Est",
"B Mean Lower Bound",
"B Mean Upper Bound",
"B Standard Deviation Est",
"B Standard Deviation Lower Bound",
"B Standard Deviation Upper Bound")
write.csv(routvdf, file = "RandomvQTL_LOD,Pvals,EffectSizes1.csv")
routv$result$mean.asymp.p
routv$result$mean.asymp.p %>% unique()
library("qtl")
library("vqtl")
routv <- scanonevar(cross = random,
mean.formula = height.in. ~ mean.QTL.add,
var.formula = ~ var.QTL.add)
routv$result$mean.asymp.p
length(routv$result$mean.asymp.p)
debug(scanonevar)
routv <- scanonevar(cross = random,
mean.formula = height.in. ~ mean.QTL.add,
var.formula = ~ var.QTL.add)
routv <- scanonevar(cross = random,
mean.formula = height.in. ~ mean.QTL.add,
var.formula = ~ var.QTL.add)
"joint" %in% scan.types
loc.idx
nrow(result)
?scanonevar
routv <- scanonevar(cross = random,
mean.formula = height.in. ~ mean.QTL.add,
var.formula = ~ var.QTL.add)
undebug(scanonevar)
routv <- scanonevar(cross = random,
mean.formula = height.in. ~ mean.QTL.add,
var.formula = ~ var.QTL.add)
routv$result$mean.asymp.p
?scanonecar
routv <- scanonevar(cross = random,
mean.formula = height.in. ~ mean.QTL.add,
var.formula = ~ var.QTL.add)
routv <- scanonevar(cross = random,
mean.formula = height.in. ~ mean.QTL.add + mean.QTL.dom,
var.formula = ~ var.QTL.add + var.QTL.dom)
routv$result$mean.asymp.p
routvdf<- data.frame(routv$result$loc.name,
routv$result$pos,
routv$result$mean.lod,
routv$result$mean.asymp.p,
routv$result$var.lod,
routv$result$var.asymp.p,
routv$result$joint.lod,
routv$result$joint.asymp.p)
colnames(routvdf) = c("SNP Names",
"Position (cM)",
"Mean LOD",
"Mean P Value",
"Variance LOD",
"Variance P Value",
"Joint LOD",
"Joint P Value")
rsizedf = sapply(y, function(x){
tempm =  effect.sizes(cross = random,
phenotype.name = "height.in.",
genotype.names = c("AA","BB"),
focal.groups = routv$result$loc.name[x])
tempv = c(tempm[1,2:7],tempm[2,2:7])
return(unlist(tempv))
})
dim(rsizedf)
routvdf<- data.frame(routv$result$loc.name,
routv$result$pos,
routv$result$mean.lod,
routv$result$mean.asymp.p,
routv$result$var.lod,
routv$result$var.asymp.p,
routv$result$joint.lod,
routv$result$joint.asymp.p)
routvdf = routvdf[-c(458,2482,2483),]
routvdf = cbind(routvdf,t(rsizedf))
colnames(routvdf) = c("SNP Name",
"Position (cM)",
"Mean LOD",
"Mean P Value",
"Variance LOD",
"Variance P Value",
"Joint LOD",
"Joint P Value",
"A Mean Est",
"A Mean Lower Bound",
"A Mean Upper Bound",
"A Standard Deviation Est",
"A Standard Deviation Lower Bound",
"A Standard Deviation Upper Bound",
"B Mean Est",
"B Mean Lower Bound",
"B Mean Upper Bound",
"B Standard Deviation Est",
"B Standard Deviation Lower Bound",
"B Standard Deviation Upper Bound")
write.csv(routvdf, file = "RandomvQTL_LOD,Pvals,EffectSizes1.csv")
#####Fam and Rand vQTL FINAL#####
library("qtl")
library("vqtl")
#read in data
random <-read.cross(file = url("https://raw.githubusercontent.com/tbillman/Stapleton-Lab/master/vQTL%20Random%20and%20Family/data/tidied/Random2.csv"))
random <- drop.nullmarkers(random)
#scan with variance
random <- calc.genoprob(random)
routv <- scanonevar(cross = random,
mean.formula = height.in. ~ mean.QTL.add + mean.QTL.dom,
var.formula = ~ var.QTL.add + var.QTL.dom)
#####Set up our own function to extract effect sizes from mean_var_plot function#####
library("dplyr")
effect.sizes = function (cross, phenotype.name, focal.groups = NULL, nuisance.groups = NULL,
genotype.names = c("AA", "AB", "BB"), xlim = NULL, ylim = NULL,
title = paste(phenotype.name, "by", paste(focal.groups,
collapse = ", ")), draw_ribbons = TRUE, se_line_size = 1,
point_size = 1)
{
indiv.mean.estim <- indiv.mean.lb <- indiv.mean.ub <- "fake_global_for_CRAN"
indiv.sd.estim <- indiv.sd.lb <- indiv.sd.ub <- "fake_global_for_CRAN"
group.mean.estim <- group.mean.ub <- group.mean.lb <- "fake_global_for_CRAN"
group.sd.estim <- group.sd.ub <- group.sd.lb <- "fake_global_for_CRAN"
modeling.df <- dplyr::data_frame(placeholder = rep(NA, qtl::nind(cross)))
modeling.df[[phenotype.name]] <- cross[["pheno"]][[phenotype.name]]
marker.names <- c(focal.groups[focal.groups %in% colnames(qtl::pull.geno(cross = cross))],
nuisance.groups[nuisance.groups %in% colnames(qtl::pull.geno(cross = cross))])
phen.names <- c(focal.groups[focal.groups %in% colnames(qtl::pull.pheno(cross = cross))],
nuisance.groups[nuisance.groups %in% colnames(qtl::pull.pheno(cross = cross))])
for (marker.name in marker.names) {
modeling.df[[marker.name]] <- factor(x = qtl::pull.geno(cross = cross)[,
marker.name], labels = genotype.names)
}
for (phen.name in phen.names) {
modeling.df[[phen.name]] <- factor(qtl::pull.pheno(cross = cross)[[phen.name]])
}
modeling.df[["placeholder"]] <- NULL
covar.form <- paste(focal.groups, collapse = "+")
if (!is.null(nuisance.groups)) {
covar.form <- paste(covar.form, "+", paste(nuisance.groups,
collapse = "+"))
}
mean.form <- paste(phenotype.name, "~", covar.form)
var.form <- paste("~", covar.form)
dglm.fit <- dglm::dglm(formula = stats::formula(mean.form),
dformula = stats::formula(var.form), data = modeling.df)
mean.pred <- stats::predict(dglm.fit, se.fit = TRUE)
mean.estim <- mean.pred$fit
mean.se <- mean.pred$se.fit
sd.pred <- stats::predict(dglm.fit$dispersion.fit, se.fit = TRUE)
sd.estim <- sd.pred$fit/sd.pred$residual.scale
sd.se <- sd.pred$se.fit
indiv.prediction.tbl <- dplyr::bind_cols(stats::na.omit(modeling.df),
dplyr::data_frame(indiv.mean.estim = mean.estim, indiv.mean.lb = mean.estim -
mean.se, indiv.mean.ub = mean.estim + mean.se, indiv.sd.estim = exp(sd.estim),
indiv.sd.lb = exp(sd.estim - sd.se), indiv.sd.ub = exp(sd.estim +
sd.se)))
group.prediction.tbl <- indiv.prediction.tbl %>% dplyr::group_by_(.dots = c(focal.groups)) %>%
dplyr::summarise(group.mean.estim = mean(indiv.mean.estim),
group.mean.lb = mean(indiv.mean.lb), group.mean.ub = mean(indiv.mean.ub),
group.sd.estim = mean(indiv.sd.estim), group.sd.lb = mean(indiv.sd.lb),
group.sd.ub = mean(indiv.sd.ub))
return(group.prediction.tbl)
}
#set up a vector to run the function on
y = 1:length(routv$result$loc.name)
#effect sizes can not be computed for these 3 SNPs so we remove them from the vector
y = y[-c(458,2482,2483)]
#populating a dataframe with effect size estimates
rsizedf = sapply(y, function(x){
tempm =  effect.sizes(cross = random,
phenotype.name = "height.in.",
genotype.names = c("AA","BB"),
focal.groups = routv$result$loc.name[x])
tempv = c(tempm[1,2:7],tempm[2,2:7])
return(unlist(tempv))
})
library(qtl)
library(vqtl)
cross = read.cross(format = "csv", file = "C:/Users/Thomas/Documents/GitHub/Stapleton-Lab/Manching BayesNet/ManchingScrubbed_GenoOnly.csv")
cross[['pheno']][['LowWater']] =
evf = read.csv(file = "C:/Users/Thomas/Documents/GitHub/Stapleton-Lab/Manching BayesNet/ManchingScrubbed_Environment.csv")
cross[['pheno']][['LowWater']] =
evf = read.csv(file = "C:/Users/Thomas/Documents/GitHub/Stapleton-Lab/Manching BayesNet/ManchingScrubbed_Environment.csv")
class(evf)
str(evf)
head(factor(evf$Low.Nitrogen))
length(factor(evf$Low.Water))
summary(cross)
-1:2
-1:-2
cross[['pheno']][['LowWater']] = factor(evf$Low.Water)[-1:-2]
cross[['pheno']][['LowNitrogen']] = factor(evf$Low.Nitrogen)[-1:-2]
cross[['pheno']][['Pathogen']] = factor(evf$Pathogen)[-1:-2]
gc()
cgp = calc.genoprob(cross = cross)
scanv = scanonevar(cross = cgp, mean.formula = Height ~LowWater + LowNitrogen + Pathogen +  mean.QTL.add ,
var.formula =  ~ LowWater + LowNitrogen + Pathogen + var.QTL.add)
gs()
gc()
scanv = scanonevar(cross = cgp, mean.formula = Height ~LowWater + LowNitrogen + Pathogen +  mean.QTL.add ,
var.formula =  ~ LowWater + LowNitrogen + Pathogen + var.QTL.add)
org <- read.table(file ="C:/Users/Thomas/Desktop/Data/Freddie1999/orig_Q11999.txt",header = FALSE, sep = "|")
dim(org)
library(parallel)
?mclapply
?scanonevar
vqtl::effects_over_genome_plot()
vqtl::effects_over_genome_plot
knitr::opts_chunk$set(echo = TRUE)
dat = read.csv(file = url("https://raw.githubusercontent.com/tbillman/Stapleton-Lab/master/Manching%20BayesNet/ManchingScrubbed.csv"))
library("bnlearn")
dat[dat$Low.Water == 1]
dat[dat$Low.Water == 1,]
dim(dat[dat$Low.Water == 1,])
mean(dat$Height)
dat$Height
mean(dat$Height)
class(dat$Height)
mean(dat$Height)[-1:-2]
which(dat$Height == NA)
dat$Height[1]
is.na(which(dat$Height == NA))
is.na(dat$Height[1]))
is.na(dat$Height[1])
is.na(dat$Height)
!is.na(dat$Height)
mean(dat$Height)[!is.na(dat$Height)]
!is.na(dat$Height)
which(!is.na(dat$Height) == T)
mean(dat$Height)[which(!is.na(dat$Height) == T)]
length(dat$Height)
unique(dat$Height)
unique(dat$Height)[3:6674]
unique(dat$Height[3:6674])
mean(dat$Height)[2:length(dat$Height)]
mean(dat$Height[2:length(dat$Height)])
mean(dat$Height[3:length(dat$Height)])
dat = dat[3:dim(dat)[1],]
mean(dat$Height)
mean(dat$Height)[which(dat$Low.Water) == 1]
mean(dat$Height)[which(dat$Low.Water == 1)]
hist(dat$Height)
unique(dat$Height)
which(dat$Height == 776)
which(dat$Height == 669)
which(dat$Height == 556)
which(dat$Height == 448)
which(dat$Height > 00)
which(dat$Height > 100)
dat$Height[1113]
dat$Height[which(dat$Height > 100)]
dat$Height[which(dat$Height > 100)] = c(48,76,69,56)
unique(dat$Height)
hist(dat$Height)
mean(dat$Height)
sd(dat$Height)
library(installr)
updateR()
#####New Set Grab Idea#####
library("MASS")
library("parallel")
i = (1.0293)^(1/12) - 1
date.read <- function(yyyymm){
as.Date(paste0(as.character(yyyymm), '01'), format='%Y%m%d')
}
nmonths <- function(end, start) {
ed <- as.POSIXlt(end)
sd <- as.POSIXlt(start)
12 * (ed$year - sd$year) + (ed$mon - sd$mon) + 1
}
set.grab <- function(orig, perfo){
sets = as.list(NULL)
a = as.character(orig$`Loan Sequence Number`)
b = as.character(perfo$`Sequence Number`)
info.matrix = outer(a,b,"==")
coor = which(info.matrix==TRUE, arr.ind = TRUE)
sets = lapply(1:length(a),function(x){
set = NULL
app = coor[which(coor[,1] == x, arr.ind = TRUE),2]
set = rbind(perfo[app,])
sets[[x]] = set
})
return(sets)
}
classify <- function(set){
if(is.null(set[dim(set)[1],]$`Zero Balance`) | is.na(set[dim(set)[1],]$`Zero Balance`)){
return("Current")
}else{
if(set[dim(set)[1],]$`Zero Balance` == 1){
return("Prepaid")
} else
if((set[dim(set)[1],]$`Zero Balance`== 3) |(set[dim(set)[1],]$`Zero Balance`== 9) ){
return("Default")
}
prepaid.npv <- function(set,i){
return(sum((set$`Current UPB` * set$`Current Interest Rate`/1200)[-dim(set)[1]],
(set$`Current UPB`[-dim(set)[1]] - set$`Current UPB`[-1]) * (1 + i)^(-1 * set$`Loan Age`[-1])) - set$`Current UPB`[1])
}
default.npv <- function(set,i){
PMT = sum((set$`Current UPB` * set$`Current Interest Rate`/1200)[-dim(set)[1]],
(set$`Current UPB`[-dim(set)[1]] - set$`Current UPB`[-1]) * (1 + i)^(-1 * set$`Loan Age`[-1]))
nreal = as.numeric(set[dim(set)[1]-1,]$`Loan Age`)
ti = nreal + nmonths(end = date.read(set[dim(set)[1],]$`Zero Balance Date`), start = date.read(set[dim(set)[1],]$`Last Paid Installment`)) - 1
vit = (1 + i)^(-ti)
OUPB = set[1,]$`Current UPB`
CUPB = set[dim(set)[1]-1,]$`Current UPB`
AL = set[dim(set)[1],]$`Actual Loss`
NPV = PMT - OUPB + vit * (CUPB + AL)
return(NPV)
}
npv = function(set, i){
set = as.data.frame(set)
status = classify(set)
if (dim(set)[1] == 1 | (!is.na(set[dim(set)[1],]$`Zero Balance`) & set[dim(set)[1],]$`Zero Balance` == 6)){
return("NA")
}
if (status == "Prepaid" | status == "Current"){
NPV = prepaid.npv(set,i)
}else{
NPV = default.npv(set,i)
}
return(NPV)
}
#####Data Entry#####
#####Using Sample Data Instead#####
org <- read.table(file ="C:/Users/Thomas/Desktop/Data/Freddie1999/sample_orig_1999.txt",header = FALSE, sep = "|")
names = c("CreditScore",
"FirstPmt",
"FirstTimeHomebuyer",
"Maturity Date",
"MSA Code",
"MI Percentage",
"Number of Units",
"Occupancy Status",
"CLTV",
"DTI",
"UPB",
"LTV",
"Interest Rate",
"Channel",
"PPM",
"Product",
"State",
"Property Type",
"Postal Code",
"Loan Sequence Number",
"Loan Purpose",
"Original Term",
"Borrower Num",
"Seller Name",
"Servicer Name",
"Super Conforming")
colnames(org) <- names
perf <- read.table(file ="C:/Users/Thomas/Desktop/Data/Freddie1999/sample_svcg_1999.txt",header = FALSE, sep = "|")
names = c("Sequence Number",
"Period",
"Current UPB",
"Delinquincy Status",
"Loan Age",
"Months to Maturity",
"Repurchased",
"Modification",
"Zero Balance",
"Zero Balance Date",
"Current Interest Rate",
"Current Deferred UPB",
"Last Paid Installment",
"MI Recoveries",
"Net Sales Proceeds",
"Non MI Recoveries",
"Expenses",
"Legal Costs",
"Maintainence and Preservation Costs",
"Tax and Insurance",
"Misc",
"Actual Loss",
"Modification Cost")
colnames(perf) = names
sq = as.numeric(perf$`Sequence Number`)
q = sq[-1] - sq[-length(sq)]
q = q*1:length(q)
q =c(0, q[q>0]); q = q + 1
#example
set1 = perf[q[1]:(q[2]-1),]
sets = lapply(2:length(q), function(x){
print(x)
return(perf[q[x-1]:(q[x]-1),])
})
npvs = lapply(sets, function(x){
print(rownames(x)[1])
return(c(as.character(x$`Sequence Number`[1]),npv(x,i)))
})
dim(org)[1]
npvs[1]
npvs[1][1]
npvs[[1]]
npvs[[1]][1]
for(i in 1:dim(org)[1]){
while(org[i]!=npvs[[j]][1]) j=j+1;
keep<-c(keep,j);
}
keep<-c();j=1;
for(i in 1:dim(org)[1]){
while(org[i]!=npvs[[j]][1]) j=j+1;
keep<-c(keep,j);
}
library("beepr")
beep()
i = 1
org[1]
org[1,]$`Loan Sequence Number`
npvs[[1]]
npvs[[1]][1]
sets[[1]]
hist(npvs)
hist(npvs[2])
hist(npvs[[]][2])
length(npvs)
realnpvs = lapply(1:length(npvs), function(x){
print(x)
return(npvs[[x]][2])
})
hist(realnpvs)
class(realnpvs)
hist(unlist(realnpvs))
class(unlist(realnpvs))
class(as.numeric(unlist(realnpvs))
)
chist(as.numeric(unlist(realnpvs)))
hist(as.numeric(unlist(realnpvs)))
max(as.numeric(unlist(realnpvs)))
realnpvs = as.numeric(unlist(lapply(1:length(npvs), function(x){
print(x)
return(npvs[[x]][2])
}))
)
unique(realnpvs)
hist(realnpvs[!is.na])
hist(realnpvs)
hist(realnpvs[which(!is.na(realnpvs))])
length(realnpvs)
length(which(!is.na(realnpvs)))
length(npvs[which(!is.na(realnpvs))])
hist(realnpvs[which(!is.na(realnpvs))])
class(realnpvs[which(!is.na(realnpvs))])
#####Working with a howell Sampleset#####
#constructing the sample
library("tidyverse")
library("qtl")
library("vqtl")
setwd("C:/Users/Thomas/Documents/GitHub/Stapleton-Lab/vQTL Howell")
